# Assembly a bacterial genome using long reads generated by the Oxford Nanopore MiniON platform.

 **After preparing the sequencing library and load it on a MiniON flowcell, [Guppy](https://nanoporetech.com/nanopore-sequencing-data-analysis) was used for basecalling. 
 A subset of six fastq files were obtained of this sequencing experiment. The following protocol describes the steps for assembly those reads into a bacterial genome**
 
 ## Obtaining the fastq files
 
 1. Loggin to Orion cluster

```console
ssh bio326-21-0@login.orion.nmbu.no
```

2. Go to the $SCRATCH folder. 
```console
[bio326-21-0@login ~]$ cd $SCRATCH/
```
3. Create a directory named GenomeAssemblyBio326 and copy from (/mnt/SCRATCH/bio326-21/GenomeAssembly/) the tarball (SalmonBacteria.rawReads.subset.tar.gz) with the fastq files and the sequencing_summary.txt file to your $SCRATCH/GenomeAssemblyBio326 directory.

```console
[bio326-21-0@login bio326-21-0]$ mkdir GenomeAssemblyBio326
[bio326-21-0@login bio326-21-0]$ cd GenomeAssemblyBio326/
[bio326-21-0@login GenomeAssemblyBio326]$ cp /mnt/SCRATCH/bio326-21/GenomeAssembly/SalmonBacteria.rawReads.subset.tar.gz .
[bio326-21-0@login GenomeAssemblyBio326]$ ls
SalmonBacteria.rawReads.subset.tar.gz
```
*If you see the SalmonBacteria.rawReads.subset.tar.gz in your new GenomeAssembly directory it means you have succeded copy this tarball.*

4. Decompress the tarball to access the files. For this, we can use the command tar and the options -x (decompress) z (gzip) v (verbose or print the results) f (file).

```console
[bio326-21-0@login GenomeAssemblyBio326]$ tar -xzvf SalmonBacteria.rawReads.subset.tar.gz
SalmonBacteria.rawReads.subset/
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_0_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_1_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_2_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_3_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_4_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_5_0.fastq
SalmonBacteria.rawReads.subset/sequencing_summary.txt
```

5. Enter to the SalmonBacteria.rawReads.subset directory and take a look:

```console
[bio326-21-0@login GenomeAssemblyBio326]$ cd SalmonBacteria.rawReads.subset

```

6. Get basic stats and quality plots of the readas in the fastq files using the [NanoPlot](https://github.com/wdecoster/NanoPlot) pipeline:

- **As we are doing some computing work, let's log into a node requesting few resources (i.e. 4G RAM, 2 CPUS for 2 hrs) using an interactive job:**

```console
(/mnt/users/auve/mycondaenvs/HTOP) [bio326-21-0@login GenomeAssemblyBio326]$ srun --cpus-per-task 2 --mem=4G --time=02:00:00 --pty bash -i
srun: job 12720658 queued and waiting for resources
srun: job 12720658 has been allocated resources

Welcome to the NMBU Orion compute cluster environment.

You are logged in to a machine that can be used to access your home directory,
edit your scripts, manage your files, and submit jobs to the cluster environment.
Do not run any jobs on this machine, as they might be automatically terminated.

IMPORTANT:
  - Orion introduction: https://orion.nmbu.no/
  - Orion can handle small-scale projects. Need more CPU hours? Please consider
    applying for national infrastructure resources: https://www.sigma2.no/
  - Please, PLEASE do compress your fastq, vcf and other non-compressed files
    using i.e. pigz.

NEWS:
  - 2020-10-08: Orion has been re-built. We are still working out many details.
    Please email us if you miss anything, or notice any issues.

For any Orion related enquiry: orion-support@nmbu.no
PS: We are on Teams: https://bit.ly/orion-teams

[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$
```
- For this protocol the NanoPlot pipeline is installed in a conda-environment (/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools). To be able of using the NanoPlot, you first need to load the module Miniconda3 and then activate the conda-environment:

```console
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ module load Miniconda3
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ source activate /net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 GenomeAssemblyBio326]$
```
*If you now see that your prompt has changed with the legend "(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools)" means the conda env has been properly loaded*

- Now let's call the program NanoPlot and see the options.

```console
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ NanoPlot --help
usage: NanoPlot [-h] [-v] [-t THREADS] [--verbose] [--store] [--raw] [--huge]
                [-o OUTDIR] [-p PREFIX] [--tsv_stats] [--maxlength N]
                [--minlength N] [--drop_outliers] [--downsample N]
                [--loglength] [--percentqual] [--alength] [--minqual N]
                [--runtime_until N] [--readtype {1D,2D,1D2}] [--barcoded]
                [--no_supplementary] [-c COLOR] [-cm COLORMAP]
                [-f {eps,jpeg,jpg,pdf,pgf,png,ps,raw,rgba,svg,svgz,tif,tiff}]
                [--plots [{kde,hex,dot,pauvre} [{kde,hex,dot,pauvre} ...]]]
                [--listcolors] [--listcolormaps] [--no-N50] [--N50]
                [--title TITLE] [--font_scale FONT_SCALE] [--dpi DPI]
                [--hide_stats]
                (--fastq file [file ...] | --fasta file [file ...] | --fastq_rich file [file ...] | --fastq_minimal file [file ...] | --summary file [file ...] | --bam file [file ...] | --ubam file [file ...] | --cram file [file ...] | --pickle pickle | --feather file [file ...])

CREATES VARIOUS PLOTS FOR LONG READ SEQUENCING DATA.
```
- We can use either the summary file, fastqfiles or a bam file with the reads to asses the quality of sequencing. For now as we have the sequencing_summary.txt file, let's use this:

```console
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ NanoPlot --summary sequencing_summary.txt --loglength -o summary-plots-log-transformed
/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools/lib/python3.6/_collections_abc.py:702: MatplotlibDeprecationWarning:

The global colormaps dictionary is no longer considered public API.

/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools/lib/python3.6/_collections_abc.py:720: MatplotlibDeprecationWarning:

The global colormaps dictionary is no longer considered public API.
```
- Although the software displayed some "warnings" it seems finished without error and produced the summary-plots-log-transformed folder:

```console
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ ls
fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_0_0.fastq  fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_3_0.fastq  sequencing_summary.txt
fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_1_0.fastq  fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_4_0.fastq  summary-plots-log-transformed
fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_2_0.fastq  fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_5_0.fastq
```

- Enter to this folder and look the results:

```console
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ cd summary-plots-log-transformed/
[bio326-21-0@cn-4 summary-plots-log-transformed]$ ls
ActivePores_Over_Time.png              LengthvsQualityScatterPlot_dot.png            NanoPlot-report.html         TimeSequencingSpeed_ViolinPlot.png
ActivityMap_ReadsPerChannel.png        LengthvsQualityScatterPlot_kde.png            NanoStats.txt                Weighted_HistogramReadlength.png
CumulativeYieldPlot_Gigabases.png      LengthvsQualityScatterPlot_loglength_dot.png  NumberOfReads_Over_Time.png  Weighted_LogTransformed_HistogramReadlength.png
CumulativeYieldPlot_NumberOfReads.png  LengthvsQualityScatterPlot_loglength_kde.png  TimeLengthViolinPlot.png     Yield_By_Length.png
Dynamic_Histogram_Read_length.html     LogTransformed_HistogramReadlength.png        TimeLogLengthViolinPlot.png
HistogramReadlength.png                NanoPlot_20210323_1252.log                    TimeQualityViolinPlot.png
```
- The pipeline produced multiple plots (png files), an html report (NanoPlot-report.html) and a text file (NanoStats.txt) with the Nanopore reads statistics. To visualize the png and html you need to copy your files to your compuer or use the GUI [Orion Jupyter hub](https://orion.nmbu.no/jupyter) to access this. However, we can take a quick view of the stats report in the text file **NanoStats.txt** using the command line.

```console
[bio326-21-0@cn-4 summary-plots-log-transformed]$ more NanoStats.txt 
General summary:         
Active channels:                   109.0
Mean read length:                4,266.4
Mean read quality:                   9.8
Median read length:              2,275.5
Median read quality:                10.0
Number of reads:                24,000.0
Read length N50:                 8,318.0
STDEV read length:               5,682.0
Total bases:               102,392,823.0
Number, percentage and megabases of reads above quality cutoffs
>Q5:	23996 (100.0%) 102.4Mb
>Q7:	22344 (93.1%) 96.3Mb
>Q10:	11983 (49.9%) 52.9Mb
>Q12:	1329 (5.5%) 4.7Mb
>Q15:	0 (0.0%) 0.0Mb
Top 5 highest mean basecall quality scores and their read lengths
1:	14.0 (772)
2:	13.9 (962)
3:	13.8 (1027)
4:	13.7 (506)
5:	13.6 (521)
Top 5 longest reads and their mean basecall quality score
1:	117332 (11.2)
2:	82149 (9.0)
3:	68986 (7.2)
4:	66931 (7.9)
5:	63998 (8.2)
```
 **This result let us know that a total of 24,000 reads are present in this subset of the MiniON sequencing experiment, with an average read lenght of 4,266 nucleotides (nt) and the largest read has a lenght of 117,332 nt. We then can continue with the assembly...**

*If you would like to copy these results files from Orion to your computer there are at least two ways for doing this: a) Using a graphic interface (i.e MobaXterm) or the command line. For MobaXterm, first open a "session to Orion" and go to cd $SCRATCH/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset/summary-plots-log-transformed  Then click on followTerminalFolder at the botom of the screen (check the image below).![moba](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/moba.png). Then you can simply select, grab and drag all the files from the left panel of mobaXterm screen to a folder on your computer*

* b) If you don't have access to MobaXterm, we can use the command line and the "secure copy" command (scp). Open a teminal in your computer type the following command:*

```console
avera@L003772:Bio326today$ scp -r bio326-21-0@login.orion.nmbu.no:/mnt/SCRATCH/bio326-21-0/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset/summary-plots-log-transformed .
```
*Command explain: scp (SecureCoPy) -r (recursive all foldersandfiles) username@remotecomputer.adress:directory/we/like/to/copy . (local computer directory)*


6. As you notice there are six fastq files in the SalmonBacteria.rawReads.subset directory. **It is often useful to concatenate all the different fastq files into one big file for downstream analyses.**

```console
[bio326-21-0@cn-4 summary-plots-log-transformed]$ cd $SCRATCH/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ cat *.fastq > SalmonBacteria.total.fastq
```

Now you have a "big" (> 100 Mb) fastq file (SalmonBacteria.total.fastq) with all the sequenced reads:

```console
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ ls -lrth
total 404M
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  32M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_1_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  32M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_0_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  37M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_5_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  35M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_4_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  34M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_3_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  32M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_2_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0 5.6M Mar 23 11:35 sequencing_summary.txt
drwxrwxr-x 2 bio326-21-0 bio326-21-0 4.0K Mar 23 12:53 summary-plots-log-transformed
-rw-rw-r-- 1 bio326-21-0 bio326-21-0 199M Mar 23 13:18 SalmonBacteria.total.fastq

```


7. As a control steep and to know if we have the same ammount of sequences (24,000) we got in the summary file in the new concatenated file, we need to count the number of reads in this "big" file. For this we can count the number of lines in the file and divide them by four (the number of canonical elements in a fastq file)...

```
A FASTQ file normally uses four lines per sequence.

Line 1 begins with a '@' character and is followed by a sequence identifier and an optional description (like a FASTA title line).
Line 2 is the raw sequence letters.
Line 3 begins with a '+' character and is optionally followed by the same sequence identifier (and any description) again.
Line 4 encodes the quality values for the sequence in Line 2, and must contain the same number of symbols as letters in the sequence.
```
Let's do it:

```console
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ echo $(wc -l < SalmonBacteria.total.fastq)/4|bc
24000
```

*Command line explained: first, we count all the lines (wc -l) of the SalmonBacteria.total.fastq file and storage into a variable ($). Then, we divided that variable \[echo $(wc -l < SalmonBacteria.total.fastq)\] by four, and in order to the computer be able to print the result we call the command bc (Basic calculator).*

Acording to this results, we have a total of 24,000 reads in the SalmonBacteria.total.fastq concatenated file, that is the same number of the total ammount of reads we got in the summary stats. 

## Assembly raw-reads into a genome (genomic contigs) using CANU assembler ###

**To recover the bacterial genome from these reads, we first need to assembly the reads into either the complete bacterial chromosome or contigs and try polish them into a final assembly. There are several bioinformatic tools (assemblers) we can used, however, in this protocol we are using [CANU](https://github.com/marbl/canu) to obtain a genomic assembly and then we will try to improve the assembly with two polishing tools: [Racon](https://github.com/isovic/racon) and [Medaka](https://github.com/nanoporetech/medaka).** 

### Running CANU

Let's check the options on CANU assembler to know what elements do we need:

- Fisrt, go back to the GenomeAssemblyBio326 folder and load the module CANU form in Orion. 

```console 
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ cd $SCRATCH/GenomeAssemblyBio326
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ module load canu/1.9-GCCcore-8.3.0-Java-11
```

- Then display the CANU's help

```console
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ canu --help

usage:   canu [-version] [-citation] \
              [-haplotype | -correct | -trim | -assemble | -trim-assemble] \
              [-s <assembly-specifications-file>] \
               -p <assembly-prefix> \
               -d <assembly-directory> \
               genomeSize=<number>[g|m|k] \
              [other-options] \
              [-haplotype{NAME} illumina.fastq.gz] \
              [-pacbio-raw |
               -pacbio-corrected |
               -nanopore-raw |
               -nanopore-corrected |
               -pacbio-hifi] file1 file2 ...

example: canu -d run1 -p godzilla genomeSize=1g -nanopore-raw reads/*.fasta.gz 
```

The help displays that we need to feed CANU with: the reads (fastq files), an output directory, a prefix (name for the files will create), the genomeSize (in this case ~4Mb) of the organism we are working on and the type of sequences (nanopore-raw). 

- As we cover all these requirements, now we can start the assembly. 

- Enter to the $SCRATCH/GenomeAssemblyBio326 folder (previously created), and make a directory named CANU.Assembly.dir

```console
[bio326-21-0@cn-4 ~]$ cd $SCRATCH/GenomeAssemblyBio326 
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ mkdir CANU.Assembly.dir
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ ls
CANU.Assembly.dir  SalmonBacteria.rawReads.subset  SalmonBacteria.rawReads.subset.tar.gz
```
- Enter to the CANU.Assembly.dir folder and copy the concatenated **SalmonBacteria.total.fastq** previously obtained (storaged in $SCRATCH/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset)

```console
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ cd CANU.Assembly.dir/
[bio326-21-0@cn-4 CANU.Assembly.dir]$ cp $SCRATCH/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset/SalmonBacteria.total.fastq .
[bio326-21-0@cn-4 CANU.Assembly.dir]$ ls
SalmonBacteria.total.fastq
```

- Finally, Let's use the following SLURM script to queue our job into the cluster. 

```bash

#!/bin/bash

## Job name:
#SBATCH --job-name=CANU
#
## Wall time limit:
#SBATCH --time=72:00:00
#
## Other parameters:
#SBATCH --cpus-per-task 16
#SBATCH --mem=20G
#SBATCH --nodes 1

## Set up job environment:

module --quiet purge  # Reset the modules to the system default
module load canu/1.9-GCCcore-8.3.0-Java-11 ##Load the canu module

##Activate conda environments

export PS1=\$

####Do some work:########

## For debuggin it is useful to print some info about the node,CPUs requested and when the job starts...
echo "Hello" $USER
echo "my submit directory is:"
echo $SLURM_SUBMIT_DIR
echo "this is the job:"
echo $SLURM_JOB_ID
echo "I am running on:"
echo $SLURM_NODELIST
echo "I am running with:"
echo $SLURM_CPUS_ON_NODE "cpus"
echo "Today is:"
date

## Copying data to local node for faster computation

cd $TMPDIR

#Check if $USER exists in $TMPDIR

if [[ -d $USER ]]
	then
        	echo "$USER exists on $TMPDIR"
	else
        	mkdir $USER
fi

echo "copying files to $TMPDIR/$USER/tmpDir_of.$SLURM_JOB_ID"

cd $USER
mkdir tmpDir_of.$SLURM_JOB_ID
cd tmpDir_of.$SLURM_JOB_ID

cp $SLURM_SUBMIT_DIR/*.fastq .

fastqfile=$(ls -l|grep fastq|awk '{print $9}')

####CANU#####

echo "Start CANU assembler at"
date +%d\ %b\ %T ##Print the day and hour the assembly starts

time canu \  
-d SalmonBacteria.canu.dir \  
-p SalmonBacteria.canu \ 
useGrid=false \ 
genomeSize=4m \
maxThreads=$SLURM_CPUS_ON_NODE \ 
maxMemory=20g \ 
-nanopore-raw $fastqfile

###########Moving results #####################

echo "moving results to" $SLURM_SUBMIT_DIR/

rm *.fastq #Remove fastq files

time cp -r * $SLURM_SUBMIT_DIR/  #Copy all results to the submit directory

####Removing tmp dir#####

cd $TMPDIR/$USER/

rm -r tmpDir_of.$SLURM_JOB_ID

echo "I've done at"
date

```
**You can either copy and paste this script into your terminal, or copy the canu.SLURM.sh file from /mnt/SCRATCH/bio326-21/GenomeAssembly to your CANU.Assembly.dir folder**

```console
[bio326-21-0@cn-4 CANU.Assembly.dir]$ cp /mnt/SCRATCH/bio326-21/GenomeAssembly/canu.SLURM.sh .
[bio326-21-0@cn-4 CANU.Assembly.dir]$ ls
canu.SLURM.sh  SalmonBacteria.total.fastq
```
- Submit the job into the Orion queue 

```console
[bio326-21-0@cn-4 CANU.Assembly.dir]$ sbatch canu.SLURM.sh
Submitted batch job 12720147
```

- Monitoring the job

```console
[bio326-21-0@login CANU.Assembly.dir]$ squeue -u $USER
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
          12720147     orion     CANU bio326-2 PD       0:00      1 (Resources)
[bio326-21-0@login CANU.Assembly.dir]$ squeue -u $USER
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
          12720147     orion     CANU bio326-2  R       0:07      1 cn-16 
[bio326-21-0@cn-4 CANU.Assembly.dir]$ ls
canu.SLURM.sh  SalmonBacteria.total.fastq  slurm-12720147.out
```

*The job is running it will take ~40 min to complete.* 

 - Once CANU has finished it will produce the **SalmonBacteria.canu.dir** directory. Let's enter to this and take a look into the assembly:

*If your job is having a long delay in the queue or shown any error after running, you can copy the CANU **SalmonBacteria.canu.dir** result directory from /mnt/SCRATCH/bio326-21/GenomeAssembly/CANU.Assembly.dir to your $SCRATCH folder using this command:* 

```bash
cp -r /mnt/SCRATCH/bio326-21/GenomeAssembly/CANU.Assembly.dir/SalmonBacteria.canu.dir $SCRATCH/GenomeAssemblyBio326/CANU.Assembly.dir
```

```console
[bio326-21-0@cn-4 CANU.Assembly.dir]$ cd SalmonBacteria.canu.dir/
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ ls
canu-logs                           SalmonBacteria.canu.contigs.layout.readToTig  SalmonBacteria.canu.seqStore.err           SalmonBacteria.canu.unitigs.fasta             trimming
canu-scripts                        SalmonBacteria.canu.contigs.layout.tigInfo    SalmonBacteria.canu.seqStore.ssi           SalmonBacteria.canu.unitigs.gfa               unitigging
correction                          SalmonBacteria.canu.correctedReads.fasta.gz   SalmonBacteria.canu.trimmedReads.fasta.gz  SalmonBacteria.canu.unitigs.layout
SalmonBacteria.canu.contigs.fasta   SalmonBacteria.canu.report                    SalmonBacteria.canu.unassembled.fasta      SalmonBacteria.canu.unitigs.layout.readToTig
SalmonBacteria.canu.contigs.layout  SalmonBacteria.canu.seqStore                  SalmonBacteria.canu.unitigs.bed            SalmonBacteria.canu.unitigs.layout.tigInfo
````
### Analyzing the CANU results. 

- To understand the results, let's take a look into the main [CANU pipeline](https://canu.readthedocs.io/en/latest/pipeline.html) ![canu pipeline](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/canu-pipeline.svg)
![canu overlap](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/canu-overlaps.svg)

- Thus the final assembled sequences (contigs) are in the **SalmonBacteria.canu.contigs.fasta** file. Let's display the first 2 lines of this fasta file:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ head -2 SalmonBacteria.canu.contigs.fasta 
>tig00000001 len=3285151 reads=10946 class=contig suggestRepeat=no suggestCircular=no
CTATTGACGGAACAAATGCGCGCTCAATAGCATCTATCGTCACGTATTCGGGCAGTACCAGCGTGGCATTGCCTGCGACCAGTGGTGACCAAAAAGCGAA
```
A very nice feature of the contigs fasta file from CANU is that it gives you in the header of each contig importat assembly metrics, as the lenght of the contig, the number of reads used to assembly that genomic fragment, if there is any repet region, and suggest circular chromosomes. We can print all this information for each contig:

- As each sequence header in a fasta file starts with a ">" symbol, we can look for all lines with that symbol in the file by:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ grep ">" SalmonBacteria.canu.contigs.fasta
>tig00000001 len=3285151 reads=10946 class=contig suggestRepeat=no suggestCircular=no
>tig00000004 len=9364 reads=164 class=contig suggestRepeat=no suggestCircular=yes
>tig00000005 len=14824 reads=160 class=contig suggestRepeat=no suggestCircular=yes
>tig00000006 len=2535 reads=56 class=contig suggestRepeat=no suggestCircular=yes
>tig00000008 len=7126 reads=85 class=contig suggestRepeat=no suggestCircular=yes
>tig00000009 len=59408 reads=207 class=contig suggestRepeat=no suggestCircular=no
>tig00000010 len=19016 reads=80 class=contig suggestRepeat=no suggestCircular=no
>tig00000014 len=60508 reads=148 class=contig suggestRepeat=no suggestCircular=yes
```

There are a total of 8 contigs in the final assembly file. Five of them are putative circular contigs. In CANU versions prior 1.9, a Graphical Fragment Assembly (GFA) file was produced. This file displays the final resolved assembly graph of all contig paths. However, the new versions of CANU has removed this feature. In this protocol we used CANU 1.9 and it produced a **SalmonBacteria.canu.unitigs.gfa** showing the contigs split at overlap junctions. We can use this to plot and visualize how the assembly would looks like (i.e. to get a graphical view of these "suggestedCircular" contigs). *It is important to notice that these graphs often would be missing edges and be over-fragmented.*

- To obtain a plot from a gfa file we can use the [Bandage](https://github.com/rrwick/Bandage) software. Bandage is installed as a singlularity container in Orion, we can load the software as follow:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ singularity exec /cvmfs/singularity.galaxyproject.org/b/a/bandage\:0.8.1--hc9558a2_2 Bandage --help
QStandardPaths: XDG_RUNTIME_DIR points to non-existing path '/run/user/4000', please create it with 0700 permissions.

  ____                  _                  
 |  _ \                | |                 
 | |_) | __ _ _ __   __| | __ _  __ _  ___ 
 |  _ < / _` | '_ \ / _` |/ _` |/ _` |/ _ \
 | |_) | (_| | | | | (_| | (_| | (_| |  __/
 |____/ \__,_|_| |_|\__,_|\__,_|\__, |\___|
                                 __/ |     
                                |___/      
Version: 0.8.1

Usage:    Bandage <command> [options]
          
Commands: <blank>      Launch the Bandage GUI
          load         Launch the Bandage GUI and load a graph file
          info         Display information about a graph
          image        Generate an image file of a graph
          querypaths   Output graph paths for BLAST queries
          reduce       Save a subgraph of a larger graph
          
Options:  --help       View this help message
          --helpall    View all command line settings
          --version    View Bandage version number
          
Online Bandage help: https://github.com/rrwick/Bandage/wiki
```

- Then we can feed this program with the **SalmonBacteria.canu.unitigs.gfa** and indicate to generate an image in png format from that graph.

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ singularity exec /cvmfs/singularity.galaxyproject.org/b/a/bandage\:0.8.1--hc9558a2_2 Bandage image SalmonBacteria.canu.unitigs.gfa SalmonBacteria.canu.unitigs.png
```

- The result is a png image displaying the union of "contigs" in the assembly graph. To open this file you need to copy to your computer or use the GUI Jupyterhub. The following plot is how this file looks like ![bandage](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/SalmonBacteria.canu.unitigs.png)

## Evaluate the length of the assembly, fragmentation, and completeness of the genome.

**As we noticed, the genomic assembly of this bacterial isolate resulted in 8 contigs. But what is the lenght of the total assembly, the largest conting and other metrics to evaluate the size and fragmentation of the genome?**

To answer this, we can obtain the total size (sum of all bases in the genome), the average lenght of the contigs and the N50-N90 statistics of the genome using the *assembly-stats* script developed by the [Sanger Institute](https://github.com/sanger-pathogens/assembly-stats).

- This software is in the conda-environment ONPTools previously loaded. *If you have not load this enviroment or was loged out the cluster, you need to activate this environmet again as in the following example:*. 
- The asssembly-stats command can be called by:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ source activate /net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ assembly-stats 
usage: stats [options] <list of fasta/q files>

Reports sequence length statistics from fasta and/or fastq files

options:
-l <int>
	Minimum length cutoff for each sequence.
	Sequences shorter than the cutoff will be ignored [1]
-s
	Print 'grep friendly' output
-t
	Print tab-delimited output
-u
	Print tab-delimited output with no header line
-v
	Print version and exit

```
- We can then give the **SalmonBacteria.canu.contigs.fasta** to this software and look the results:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ assembly-stats  SalmonBacteria.canu.contigs.fasta 
stats for SalmonBacteria.canu.contigs.fasta
sum = 3457932, n = 8, ave = 432241.50, largest = 3285151
N50 = 3285151, n = 1
N60 = 3285151, n = 1
N70 = 3285151, n = 1
N80 = 3285151, n = 1
N90 = 3285151, n = 1
N100 = 2535, n = 8
N_count = 0
Gaps = 0
```
**The total of bases in the assembly sum ~3.46 Mb, this is the final length of the assembly. The N50 (statistic that defines the assembly quality in terms of contiguity. It can be defined as: given a set of contigs, the N50 is the sequence length of the shortest contig at 50% of the total genome length...), is ~ 3.28 Mb in a single contig.**

Finally, we can assess the completeness of our genome. The most used strategy is to look for the presence of a set of single-copy orthologs genes commonly present in all bacteria (universal genes) and score the number of occurrences in our genome. 

### Evaluate genome completeness by BUSCO

[BUSCO](https://busco.ezlab.org/) (Benchmarking Universal Single-Copy Orthologs) is a tool that attempts to provide a quantitative assessment of the completeness in terms of expected gene content of a genome assembly, transcriptome, or annotated gene set. The results are simplified into categories of Complete and single-copy, Complete and duplicated, Fragmented, or Missing BUSCOs.

This software looks for a certain number of orthologous genes (BUSCOs) on a database and compares the total of these ortholog genes present in the genome we would like to evaluate. Then, it estimates the completeness based on the presence, duplication, fragmentation, or absence of these BUSCOS. For example (raw example), if the BUSCO database has 10 genes and the software only finds 9 of them in the query genome it scores completeness of the genome at 90 %.

BUSCO has developed different databases with common universal orthologs clusters for several organisms:
![buscoimg](https://github.com/avera1988/Genome_Assembly_lecture/blob/master/images/busco.png)

Busco will predict genes in the assembly (by prodigal) and then look for the USCOs of a certain taxonomical lineage using hmmer. It automatically identifies the closest taxonomical lineage and then download the BUSCOs database, however you can indicate and narrow the BUSCOs sarch to a prokaryote or eukaryote database by using the **--auto-lineage-prok** flag. 

- BUSCO is installed in Orion by a singularity container. We can use the following command to look into the busco options:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ singularity exec /cvmfs/singularity.galaxyproject.org/b/u/busco\:5.0.0--py_1 busco --help
sage: busco -i [SEQUENCE_FILE] -l [LINEAGE] -o [OUTPUT_NAME] -m [MODE] [OTHER OPTIONS]

Welcome to BUSCO 5.0.0: the Benchmarking Universal Single-Copy Ortholog assessment tool.
For more detailed usage information, please review the README file provided with this distribution and the BUSCO user guide.

optional arguments:
  -i FASTA FILE, --in FASTA FILE
                        Input sequence file in FASTA format. Can be an assembled genome or transcriptome (DNA), or protein sequences from an annotated gene set.
  -o OUTPUT, --out OUTPUT
                        Give your analysis run a recognisable short name. Output folders and files will be labelled with this name. WARNING: do not provide a path
  -m MODE, --mode MODE  Specify which BUSCO analysis mode to run.
                        There are three valid modes:
                        - geno or genome, for genome assemblies (DNA)
                        - tran or transcriptome, for transcriptome assemblies (DNA)
                        - prot or proteins, for annotated gene sets (protein)
  -l LINEAGE, --lineage_dataset LINEAGE
                        Specify the name of the BUSCO lineage to be used.
  --auto-lineage        Run auto-lineage to find optimum lineage path
  --auto-lineage-prok   Run auto-lineage just on non-eukaryote trees to find optimum lineage path
  --auto-lineage-euk    Run auto-placement just on eukaryote tree to find optimum lineage path
  -c N, --cpu N         Specify the number (N=integer) of threads/cores to use.
  -f, --force           Force rewriting of existing files. Must be used when output files with the provided name already exist.
  -r, --restart         Continue a run that had already partially completed.
  -q, --quiet           Disable the info logs, displays only errors
  --out_path OUTPUT_PATH
                        Optional location for results folder, excluding results folder name. Default is current working directory.
  --download_path DOWNLOAD_PATH
                        Specify local filepath for storing BUSCO dataset downloads
  --datasets_version DATASETS_VERSION
                        Specify the version of BUSCO datasets, e.g. odb10
  --download_base_url DOWNLOAD_BASE_URL
                        Set the url to the remote BUSCO dataset location
  --update-data         Download and replace with last versions all lineages datasets and files necessary to their automated selection
  --offline             To indicate that BUSCO cannot attempt to download files
  --metaeuk_parameters METAEUK_PARAMETERS
                        Pass additional arguments to Metaeuk for the first run. All arguments should be contained within a single pair of quotation marks, separated by commas. E.g. "--param1=1,--param2=2"
  --metaeuk_rerun_parameters METAEUK_RERUN_PARAMETERS
                        Pass additional arguments to Metaeuk for the second run. All arguments should be contained within a single pair of quotation marks, separated by commas. E.g. "--param1=1,--param2=2"
  -e N, --evalue N      E-value cutoff for BLAST searches. Allowed formats, 0.001 or 1e-03 (Default: 1e-03)
  --limit REGION_LIMIT  How many candidate regions (contig or transcript) to consider per BUSCO (default: 3)
  --augustus            Use augustus gene predictor for eukaryote runs
  --augustus_parameters AUGUSTUS_PARAMETERS
                        Pass additional arguments to Augustus. All arguments should be contained within a single pair of quotation marks, separated by commas. E.g. "--param1=1,--param2=2"
  --augustus_species AUGUSTUS_SPECIES
                        Specify a species for Augustus training.
  --long                Optimization Augustus self-training mode (Default: Off); adds considerably to the run time, but can improve results for some non-model organisms
  --config CONFIG_FILE  Provide a config file
  -v, --version         Show this version and exit
  -h, --help            Show this help message and exit
  --list-datasets       Print the list of available BUSCO datasets
  ```
 
We need to indicate the genome.fasta file we are using as a query, the lineage (in this case --auto-lineage-prok), the mode (genome) and the output prefix. **As BUSCO works more eficiently with multiple CPUs, the best option for running this program is by submitting a job in to the Orion queue.**

- The following busco.SLURM.sh script can be used for submiting BUSCO to the Orion queue.

```bash
#!/bin/bash

## Job name:
#SBATCH --job-name=BUSCOBacteria
#
## Wall time limit:
#SBATCH --time=00:30:00
#
## Other parameters:
#SBATCH --cpus-per-task 10
#SBATCH --mem=10G
#SBATCH --nodes 1
#SBATCH --partition=smallmem

## Set up job environment:

module --quiet purge  # Reset the modules to the system default

####Do some work:########

## For debuggin it is useful to print some info about the node,CPUs requested and when the job starts...
echo "Hello" $USER
echo "my submit directory is:"
echo $SLURM_SUBMIT_DIR
echo "this is the job:"
echo $SLURM_JOB_ID
echo "I am running on:"
echo $SLURM_NODELIST
echo "I am running with:"
echo $SLURM_CPUS_ON_NODE "cpus"
echo "Today is:"
date

## Copying data to local node for faster computation

cd $TMPDIR

#Check if $USER exists in $TMPDIR

if [[ -d $USER ]]
	then
        	echo "$USER exists on $TMPDIR"
	else
        	mkdir $USER
fi

echo "copying files to $TMPDIR/$USER/tmpDir_of.$SLURM_JOB_ID"

cd $USER
mkdir tmpDir_of.$SLURM_JOB_ID
cd tmpDir_of.$SLURM_JOB_ID

cp $SLURM_SUBMIT_DIR/*.canu.contigs.fasta .

fasta=$(ls -1|grep canu.contigs.fasta)

####RUNNING BUSCO####

echo "Busco starts at"
date +%d\ %b\ %T

singularity exec /cvmfs/singularity.galaxyproject.org/b/u/busco\:5.0.0--py_1 busco \
-i $fasta \
-o Salmon.bacteria.busco \
-m geno \
--auto-lineage-prok \
-c $SLURM_CPUS_ON_NODE

###########Moving results #####################

echo "moving results to" $SLURM_SUBMIT_DIR/

rm *.fasta #Remove fastq files
rm -r busco_downloads #Remove temp busco database downloads

time cp -r * $SLURM_SUBMIT_DIR/  #Copy all results to the submit directory

####Removing tmp dir#####

cd $TMPDIR/$USER/

rm -r tmpDir_of.$SLURM_JOB_ID

echo "I've done at"
date
```
*A copy of this script can be found at /mnt/SCRATCH/bio326-21/GenomeAssembly*

- Let's submit this script into Orion queue:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ cp /mnt/SCRATCH/bio326-21/GenomeAssembly/busco.SLURM.sh .
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ sbatch busco.SLURM.sh
Submitted batch job 12720972
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ squeue -u $USER
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
          12720785     orion     bash bio326-2  R    1:48:19      1 cn-4 
          12720976  smallmem BUSCOBac bio326-2 PD       0:00      1 (Priority)
```

- After finishig, the job will create a **Salmon.bacteria.busco** directory. Let's enter to it and take a look:

*If your job has not started, it is taking a long time in the queue or proudce any error, you can find the results of the BUSCO analysis in the /mnt/SCRATCH/bio326-21/GenomeAssembly/Salmon.bacteria.busco folder, just copy and paste this folder to your $SCRATCH/GenomeAssembly/SalmonBacteria.canu.dir folder by:*

```bash
cp -r /mnt/SCRATCH/bio326-21/GenomeAssembly/Salmon.bacteria.busco $SCRATCH/GenomeAssemblyBio326/CANU.Assembly.dir/SalmonBacteria.canu.dir
```

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ cd Salmon.bacteria.busco/
[bio326-21-0@cn-4 Salmon.bacteria.busco]$ ls
auto_lineage  prodigal_output     run_pseudomonadales_odb10                                       short_summary.specific.pseudomonadales_odb10.Salmon.bacteria.busco.txt
logs          run_bacteria_odb10  short_summary.generic.bacteria_odb10.Salmon.bacteria.busco.txt
```
It creates a prodigal_output folder with all the predicted genes of the genome used as query as well as two directories with the hmmer results (run_bacteria_odb10 and run_pseudomonadales_odb10). BUSCO has automatically identified that our organism is a bacterium (short_summary.generic.bacteria_odb10.Salmon.bacteria.busco.txt) and it belongs to the pseudomonadales order (short_summary.specific.pseudomonadales_odb10.Salmon.bacteria.busco.txt). Then let's look into the summary to check the assembly completeness of our genome:

```console
bio326-21-0@login Salmon.bacteria.busco]$ more short_summary.specific.pseudomonadales_odb10.Salmon.bacteria.busco.txt 
# BUSCO version is: 5.0.0 
# The lineage dataset is: pseudomonadales_odb10 (Creation date: 2020-03-06, number of species: 159, number of BUSCOs: 782)
# Summarized benchmarking in BUSCO notation for file /home/work/bio326-21-0/tmpDir_of.12720976/SalmonBacteria.canu.contigs.fasta
# BUSCO was run in mode: genome
# Gene predictor used: prodigal

	***** Results: *****

	C:27.6%[S:27.6%,D:0.0%],F:17.9%,M:54.5%,n:782	   
	216	Complete BUSCOs (C)			   
	216	Complete and single-copy BUSCOs (S)	   
	0	Complete and duplicated BUSCOs (D)	   
	140	Fragmented BUSCOs (F)			   
	426	Missing BUSCOs (M)			   
	782	Total BUSCO groups searched	
```

**Accordingly to BUSCO, the bacterial genome recovered in this experiment is only 27 % complete. Most of the genes are missing or fragmented.**

## Improving the assembly by Racon and Medaka polisher tools...
