# Assembly a bacterial genome using long reads generated by the Oxford Nanopore MiniON platform.

 **After preparing the sequencing library and load it on a MiniON flowcell, [Guppy](https://nanoporetech.com/nanopore-sequencing-data-analysis) was used for basecalling. 
 A subset of six fastq files were obtained of this sequencing experiment. The following protocol describes the steps for assembly those reads into a bacterial genome**
 
 ## Obtaining the fastq files
 
 1. Loggin to Orion cluster

```console
ssh bio326-21-0@login.orion.nmbu.no
```

2. Go to the $SCRATCH folder. 
```console
[bio326-21-0@login ~]$ cd $SCRATCH/
```
3. Create a directory named GenomeAssemblyBio326 and copy from (/mnt/SCRATCH/bio326-21/GenomeAssembly/) the tarball (SalmonBacteria.rawReads.subset.tar.gz) with the fastq files and the sequencing_summary.txt file to your $SCRATCH/GenomeAssemblyBio326 directory.

```console
[bio326-21-0@login bio326-21-0]$ mkdir GenomeAssemblyBio326
[bio326-21-0@login bio326-21-0]$ cd GenomeAssemblyBio326/
[bio326-21-0@login GenomeAssemblyBio326]$ cp /mnt/SCRATCH/bio326-21/GenomeAssembly/SalmonBacteria.rawReads.subset.tar.gz .
[bio326-21-0@login GenomeAssemblyBio326]$ ls
SalmonBacteria.rawReads.subset.tar.gz
```
*If you see the SalmonBacteria.rawReads.subset.tar.gz in your new GenomeAssembly directory it means you have succeded copy this tarball.*

4. Decompress the tarball to access the files. For this, we can use the command tar and the options -x (decompress) z (gzip) v (verbose or print the results) f (file).

```console
[bio326-21-0@login GenomeAssemblyBio326]$ tar -xzvf SalmonBacteria.rawReads.subset.tar.gz
SalmonBacteria.rawReads.subset/
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_0_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_1_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_2_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_3_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_4_0.fastq
SalmonBacteria.rawReads.subset/fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_5_0.fastq
SalmonBacteria.rawReads.subset/sequencing_summary.txt
```

5. Enter to the SalmonBacteria.rawReads.subset directory and take a look:

```console
[bio326-21-0@login GenomeAssemblyBio326]$ cd SalmonBacteria.rawReads.subset

```

6. Get basic stats and quality plots of the readas in the fastq files using the [NanoPlot](https://github.com/wdecoster/NanoPlot) pipeline:

- **As we are doing some computing work, let's log into a node requesting few resources (i.e. 4G RAM, 2 CPUS for 2 hrs) using an interactive job:**

```console
(/mnt/users/auve/mycondaenvs/HTOP) [bio326-21-0@login GenomeAssemblyBio326]$ srun --cpus-per-task 2 --mem=4G --time=02:00:00 --pty bash -i
srun: job 12720658 queued and waiting for resources
srun: job 12720658 has been allocated resources

Welcome to the NMBU Orion compute cluster environment.

You are logged in to a machine that can be used to access your home directory,
edit your scripts, manage your files, and submit jobs to the cluster environment.
Do not run any jobs on this machine, as they might be automatically terminated.

IMPORTANT:
  - Orion introduction: https://orion.nmbu.no/
  - Orion can handle small-scale projects. Need more CPU hours? Please consider
    applying for national infrastructure resources: https://www.sigma2.no/
  - Please, PLEASE do compress your fastq, vcf and other non-compressed files
    using i.e. pigz.

NEWS:
  - 2020-10-08: Orion has been re-built. We are still working out many details.
    Please email us if you miss anything, or notice any issues.

For any Orion related enquiry: orion-support@nmbu.no
PS: We are on Teams: https://bit.ly/orion-teams

[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$
```
- For this protocol the NanoPlot pipeline is installed in a conda-environment (/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools). To be able of using the NanoPlot, you first need to load the module Miniconda3 and then activate the conda-environment:

```console
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ module load Miniconda3
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ source activate /net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 GenomeAssemblyBio326]$
```
*If you now see that your prompt has changed with the legend "(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools)" means the conda env has been properly loaded*

- Now let's call the program NanoPlot and see the options.

```console
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ NanoPlot --help
usage: NanoPlot [-h] [-v] [-t THREADS] [--verbose] [--store] [--raw] [--huge]
                [-o OUTDIR] [-p PREFIX] [--tsv_stats] [--maxlength N]
                [--minlength N] [--drop_outliers] [--downsample N]
                [--loglength] [--percentqual] [--alength] [--minqual N]
                [--runtime_until N] [--readtype {1D,2D,1D2}] [--barcoded]
                [--no_supplementary] [-c COLOR] [-cm COLORMAP]
                [-f {eps,jpeg,jpg,pdf,pgf,png,ps,raw,rgba,svg,svgz,tif,tiff}]
                [--plots [{kde,hex,dot,pauvre} [{kde,hex,dot,pauvre} ...]]]
                [--listcolors] [--listcolormaps] [--no-N50] [--N50]
                [--title TITLE] [--font_scale FONT_SCALE] [--dpi DPI]
                [--hide_stats]
                (--fastq file [file ...] | --fasta file [file ...] | --fastq_rich file [file ...] | --fastq_minimal file [file ...] | --summary file [file ...] | --bam file [file ...] | --ubam file [file ...] | --cram file [file ...] | --pickle pickle | --feather file [file ...])

CREATES VARIOUS PLOTS FOR LONG READ SEQUENCING DATA.
```
- We can use either the summary file, fastqfiles or a bam file with the reads to asses the quality of sequencing. For now as we have the sequencing_summary.txt file, let's use this:

```console
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ NanoPlot --summary sequencing_summary.txt --loglength -o summary-plots-log-transformed
/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools/lib/python3.6/_collections_abc.py:702: MatplotlibDeprecationWarning:

The global colormaps dictionary is no longer considered public API.

/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools/lib/python3.6/_collections_abc.py:720: MatplotlibDeprecationWarning:

The global colormaps dictionary is no longer considered public API.
```
- Although the software displayed some "warnings" it seems finished without error and produced the summary-plots-log-transformed folder:

```console
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ ls
fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_0_0.fastq  fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_3_0.fastq  sequencing_summary.txt
fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_1_0.fastq  fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_4_0.fastq  summary-plots-log-transformed
fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_2_0.fastq  fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_5_0.fastq
```

- Enter to this folder and look the results:

```console
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ cd summary-plots-log-transformed/
[bio326-21-0@cn-4 summary-plots-log-transformed]$ ls
ActivePores_Over_Time.png              LengthvsQualityScatterPlot_dot.png            NanoPlot-report.html         TimeSequencingSpeed_ViolinPlot.png
ActivityMap_ReadsPerChannel.png        LengthvsQualityScatterPlot_kde.png            NanoStats.txt                Weighted_HistogramReadlength.png
CumulativeYieldPlot_Gigabases.png      LengthvsQualityScatterPlot_loglength_dot.png  NumberOfReads_Over_Time.png  Weighted_LogTransformed_HistogramReadlength.png
CumulativeYieldPlot_NumberOfReads.png  LengthvsQualityScatterPlot_loglength_kde.png  TimeLengthViolinPlot.png     Yield_By_Length.png
Dynamic_Histogram_Read_length.html     LogTransformed_HistogramReadlength.png        TimeLogLengthViolinPlot.png
HistogramReadlength.png                NanoPlot_20210323_1252.log                    TimeQualityViolinPlot.png
```
- The pipeline produced multiple plots (png files), an html report (NanoPlot-report.html) and a text file (NanoStats.txt) with the Nanopore reads statistics. To visualize the png and html you need to copy your files to your compuer or use the GUI [Orion Jupyter hub](https://orion.nmbu.no/jupyter) to access this. However, we can take a quick view of the stats report in the text file **NanoStats.txt** using the command line.

```console
[bio326-21-0@cn-4 summary-plots-log-transformed]$ more NanoStats.txt 
General summary:         
Active channels:                   109.0
Mean read length:                4,266.4
Mean read quality:                   9.8
Median read length:              2,275.5
Median read quality:                10.0
Number of reads:                24,000.0
Read length N50:                 8,318.0
STDEV read length:               5,682.0
Total bases:               102,392,823.0
Number, percentage and megabases of reads above quality cutoffs
>Q5:	23996 (100.0%) 102.4Mb
>Q7:	22344 (93.1%) 96.3Mb
>Q10:	11983 (49.9%) 52.9Mb
>Q12:	1329 (5.5%) 4.7Mb
>Q15:	0 (0.0%) 0.0Mb
Top 5 highest mean basecall quality scores and their read lengths
1:	14.0 (772)
2:	13.9 (962)
3:	13.8 (1027)
4:	13.7 (506)
5:	13.6 (521)
Top 5 longest reads and their mean basecall quality score
1:	117332 (11.2)
2:	82149 (9.0)
3:	68986 (7.2)
4:	66931 (7.9)
5:	63998 (8.2)
```
 **This result let us know that a total of 24,000 reads are present in this subset of the MiniON sequencing experiment, with an average read lenght of 4,266 nucleotides (nt) and the largest read has a lenght of 117,332 nt. We then can continue with the assembly...**

*If you would like to copy these results files from Orion to your computer there are at least two ways for doing this: a) Using a graphic interface (i.e MobaXterm) or the command line. For MobaXterm, first open a "session to Orion" and go to cd $SCRATCH/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset/summary-plots-log-transformed  Then click on followTerminalFolder at the botom of the screen (check the image below).![moba](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/moba.png). Then you can simply select, grab and drag all the files from the left panel of mobaXterm screen to a folder on your computer*

*b) If you don't have access to MobaXterm, we can use the command line and the "secure copy" command (scp). Open a teminal in your computer type the following command:*

```console
avera@L003772:Bio326today$ scp -r bio326-21-0@login.orion.nmbu.no:/mnt/SCRATCH/bio326-21-0/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset/summary-plots-log-transformed .
```
*Command explain: scp (SecureCoPy) -r (recursive all foldersandfiles) username@remotecomputer.adress:directory/we/like/to/copy . (local computer directory)*


6. As you notice there are six fastq files in the SalmonBacteria.rawReads.subset directory. **It is often useful to concatenate all the different fastq files into one big file for downstream analyses.**

```console
[bio326-21-0@cn-4 summary-plots-log-transformed]$ cd $SCRATCH/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ cat *.fastq > SalmonBacteria.total.fastq
```

Now you have a "big" (> 100 Mb) fastq file (SalmonBacteria.total.fastq) with all the sequenced reads:

```console
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ ls -lrth
total 404M
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  32M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_1_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  32M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_0_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  37M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_5_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  35M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_4_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  34M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_3_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0  32M Mar 22 16:17 fastq_runid_cbaffd65431ed3590f2402612142061571365f8a_2_0.fastq
-rwxrwxr-x 1 bio326-21-0 bio326-21-0 5.6M Mar 23 11:35 sequencing_summary.txt
drwxrwxr-x 2 bio326-21-0 bio326-21-0 4.0K Mar 23 12:53 summary-plots-log-transformed
-rw-rw-r-- 1 bio326-21-0 bio326-21-0 199M Mar 23 13:18 SalmonBacteria.total.fastq

```


7. As a control steep and to know if we have the same ammount of sequences (24,000) we got in the summary file in the new concatenated file, we need to count the number of reads in this "big" file. For this we can count the number of lines in the file and divide them by four (the number of canonical elements in a fastq file)...

```
A FASTQ file normally uses four lines per sequence.

Line 1 begins with a '@' character and is followed by a sequence identifier and an optional description (like a FASTA title line).
Line 2 is the raw sequence letters.
Line 3 begins with a '+' character and is optionally followed by the same sequence identifier (and any description) again.
Line 4 encodes the quality values for the sequence in Line 2, and must contain the same number of symbols as letters in the sequence.
```
Let's do it:

```console
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ echo $(wc -l < SalmonBacteria.total.fastq)/4|bc
24000
```

*Command line explained: first, we count all the lines (wc -l) of the SalmonBacteria.total.fastq file and storage into a variable ($). Then, we divided that variable \[echo $(wc -l < SalmonBacteria.total.fastq)\] by four, and in order to the computer be able to print the result we call the command bc (Basic calculator).*

Acording to this results, we have a total of 24,000 reads in the SalmonBacteria.total.fastq concatenated file, that is the same number of the total ammount of reads we got in the summary stats. 

## Assembly raw-reads into a genome (genomic contigs) using CANU assembler ###

**To recover the bacterial genome from these reads, we first need to assembly the reads into either the complete bacterial chromosome or contigs and try polish them into a final assembly. There are several bioinformatic tools (assemblers) we can used, however, in this protocol we are using [CANU](https://github.com/marbl/canu) to obtain a genomic assembly and then we will try to improve the assembly with two polishing tools: [Racon](https://github.com/isovic/racon) and [Medaka](https://github.com/nanoporetech/medaka).** 

### Running CANU

Let's check the options on CANU assembler to know what elements do we need:

- Fisrt, go back to the GenomeAssemblyBio326 folder and load the module CANU form in Orion. 

```console 
[bio326-21-0@cn-4 SalmonBacteria.rawReads.subset]$ cd $SCRATCH/GenomeAssemblyBio326
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ module load canu/1.9-GCCcore-8.3.0-Java-11
```

- Then display the CANU's help

```console
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ canu --help

usage:   canu [-version] [-citation] \
              [-haplotype | -correct | -trim | -assemble | -trim-assemble] \
              [-s <assembly-specifications-file>] \
               -p <assembly-prefix> \
               -d <assembly-directory> \
               genomeSize=<number>[g|m|k] \
              [other-options] \
              [-haplotype{NAME} illumina.fastq.gz] \
              [-pacbio-raw |
               -pacbio-corrected |
               -nanopore-raw |
               -nanopore-corrected |
               -pacbio-hifi] file1 file2 ...

example: canu -d run1 -p godzilla genomeSize=1g -nanopore-raw reads/*.fasta.gz 
```

The help displays that we need to feed CANU with: the reads (fastq files), an output directory, a prefix (name for the files will create), the genomeSize (in this case ~4Mb) of the organism we are working on and the type of sequences (nanopore-raw). 

- As we cover all these requirements, now we can start the assembly. 

- Enter to the $SCRATCH/GenomeAssemblyBio326 folder (previously created), and make a directory named CANU.Assembly.dir

```console
[bio326-21-0@cn-4 ~]$ cd $SCRATCH/GenomeAssemblyBio326 
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ mkdir CANU.Assembly.dir
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ ls
CANU.Assembly.dir  SalmonBacteria.rawReads.subset  SalmonBacteria.rawReads.subset.tar.gz
```
- Enter to the CANU.Assembly.dir folder and copy the concatenated **SalmonBacteria.total.fastq** previously obtained (storaged in $SCRATCH/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset)

```console
[bio326-21-0@cn-4 GenomeAssemblyBio326]$ cd CANU.Assembly.dir/
[bio326-21-0@cn-4 CANU.Assembly.dir]$ cp $SCRATCH/GenomeAssemblyBio326/SalmonBacteria.rawReads.subset/SalmonBacteria.total.fastq .
[bio326-21-0@cn-4 CANU.Assembly.dir]$ ls
SalmonBacteria.total.fastq
```

- Finally, Let's use the following SLURM script to queue our job into the cluster. 

```bash

#!/bin/bash

## Job name:
#SBATCH --job-name=CANU
#
## Wall time limit:
#SBATCH --time=72:00:00
#
## Other parameters:
#SBATCH --cpus-per-task 16
#SBATCH --mem=20G
#SBATCH --nodes 1

## Set up job environment:

module --quiet purge  # Reset the modules to the system default
module load canu/1.9-GCCcore-8.3.0-Java-11 ##Load the canu module

##Activate conda environments

export PS1=\$

####Do some work:########

## For debuggin it is useful to print some info about the node,CPUs requested and when the job starts...
echo "Hello" $USER
echo "my submit directory is:"
echo $SLURM_SUBMIT_DIR
echo "this is the job:"
echo $SLURM_JOB_ID
echo "I am running on:"
echo $SLURM_NODELIST
echo "I am running with:"
echo $SLURM_CPUS_ON_NODE "cpus"
echo "Today is:"
date

## Copying data to local node for faster computation

cd $TMPDIR

#Check if $USER exists in $TMPDIR

if [[ -d $USER ]]
	then
        	echo "$USER exists on $TMPDIR"
	else
        	mkdir $USER
fi

echo "copying files to $TMPDIR/$USER/tmpDir_of.$SLURM_JOB_ID"

cd $USER
mkdir tmpDir_of.$SLURM_JOB_ID
cd tmpDir_of.$SLURM_JOB_ID

cp $SLURM_SUBMIT_DIR/*.fastq .

fastqfile=$(ls -l|grep fastq|awk '{print $9}')

####CANU#####

echo "Start CANU assembler at"
date +%d\ %b\ %T ##Print the day and hour the assembly starts

time canu \  
-d SalmonBacteria.canu.dir \  
-p SalmonBacteria.canu \ 
useGrid=false \ 
genomeSize=4m \
maxThreads=$SLURM_CPUS_ON_NODE \ 
maxMemory=20g \ 
-nanopore-raw $fastqfile

###########Moving results #####################

echo "moving results to" $SLURM_SUBMIT_DIR/

rm *.fastq #Remove fastq files

time cp -r * $SLURM_SUBMIT_DIR/  #Copy all results to the submit directory

####Removing tmp dir#####

cd $TMPDIR/$USER/

rm -r tmpDir_of.$SLURM_JOB_ID

echo "I've done at"
date

```
**You can either copy and paste this script into your terminal, or copy the canu.SLURM.sh file from /mnt/SCRATCH/bio326-21/GenomeAssembly to your CANU.Assembly.dir folder**

```console
[bio326-21-0@cn-4 CANU.Assembly.dir]$ cp /mnt/SCRATCH/bio326-21/GenomeAssembly/canu.SLURM.sh .
[bio326-21-0@cn-4 CANU.Assembly.dir]$ ls
canu.SLURM.sh  SalmonBacteria.total.fastq
```
- Submit the job into the Orion queue 

```console
[bio326-21-0@cn-4 CANU.Assembly.dir]$ sbatch canu.SLURM.sh
Submitted batch job 12720147
```

- Monitoring the job

```console
[bio326-21-0@login CANU.Assembly.dir]$ squeue -u $USER
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
          12720147     orion     CANU bio326-2 PD       0:00      1 (Resources)
[bio326-21-0@login CANU.Assembly.dir]$ squeue -u $USER
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
          12720147     orion     CANU bio326-2  R       0:07      1 cn-16 
[bio326-21-0@cn-4 CANU.Assembly.dir]$ ls
canu.SLURM.sh  SalmonBacteria.total.fastq  slurm-12720147.out
```

*The job is running it will take ~40 min to complete.* 

 - Once CANU has finished it will produce the **SalmonBacteria.canu.dir** directory. Let's enter to this and take a look into the assembly:

*If your job is having a long delay in the queue or shown any error after running, you can copy the CANU **SalmonBacteria.canu.dir** result directory from /mnt/SCRATCH/bio326-21/GenomeAssembly/CANU.Assembly.dir to your $SCRATCH folder using this command:* 

```bash
cp -r /mnt/SCRATCH/bio326-21/GenomeAssembly/CANU.Assembly.dir/SalmonBacteria.canu.dir $SCRATCH/GenomeAssemblyBio326/CANU.Assembly.dir
```

```console
[bio326-21-0@cn-4 CANU.Assembly.dir]$ cd SalmonBacteria.canu.dir/
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ ls
canu-logs                           SalmonBacteria.canu.contigs.layout.readToTig  SalmonBacteria.canu.seqStore.err           SalmonBacteria.canu.unitigs.fasta             trimming
canu-scripts                        SalmonBacteria.canu.contigs.layout.tigInfo    SalmonBacteria.canu.seqStore.ssi           SalmonBacteria.canu.unitigs.gfa               unitigging
correction                          SalmonBacteria.canu.correctedReads.fasta.gz   SalmonBacteria.canu.trimmedReads.fasta.gz  SalmonBacteria.canu.unitigs.layout
SalmonBacteria.canu.contigs.fasta   SalmonBacteria.canu.report                    SalmonBacteria.canu.unassembled.fasta      SalmonBacteria.canu.unitigs.layout.readToTig
SalmonBacteria.canu.contigs.layout  SalmonBacteria.canu.seqStore                  SalmonBacteria.canu.unitigs.bed            SalmonBacteria.canu.unitigs.layout.tigInfo
````
### Analyzing the CANU results. 

- To understand the results, let's take a look into the main [CANU pipeline](https://canu.readthedocs.io/en/latest/pipeline.html) ![canu pipeline](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/canu-pipeline.svg)
![canu overlap](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/canu-overlaps.svg)

- Thus the final assembled sequences (contigs) are in the **SalmonBacteria.canu.contigs.fasta** file. Let's display the first 2 lines of this fasta file:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ head -2 SalmonBacteria.canu.contigs.fasta 
>tig00000001 len=3285151 reads=10946 class=contig suggestRepeat=no suggestCircular=no
CTATTGACGGAACAAATGCGCGCTCAATAGCATCTATCGTCACGTATTCGGGCAGTACCAGCGTGGCATTGCCTGCGACCAGTGGTGACCAAAAAGCGAA
```
A very nice feature of the contigs fasta file from CANU is that it gives you in the header of each contig importat assembly metrics, as the lenght of the contig, the number of reads used to assembly that genomic fragment, if there is any repet region, and suggest circular chromosomes. We can print all this information for each contig:

- As each sequence header in a fasta file starts with a ">" symbol, we can look for all lines with that symbol in the file by:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ grep ">" SalmonBacteria.canu.contigs.fasta
>tig00000001 len=3285151 reads=10946 class=contig suggestRepeat=no suggestCircular=no
>tig00000004 len=9364 reads=164 class=contig suggestRepeat=no suggestCircular=yes
>tig00000005 len=14824 reads=160 class=contig suggestRepeat=no suggestCircular=yes
>tig00000006 len=2535 reads=56 class=contig suggestRepeat=no suggestCircular=yes
>tig00000008 len=7126 reads=85 class=contig suggestRepeat=no suggestCircular=yes
>tig00000009 len=59408 reads=207 class=contig suggestRepeat=no suggestCircular=no
>tig00000010 len=19016 reads=80 class=contig suggestRepeat=no suggestCircular=no
>tig00000014 len=60508 reads=148 class=contig suggestRepeat=no suggestCircular=yes
```

There are a total of 8 contigs in the final assembly file. Five of them are putative circular contigs. In CANU versions prior 1.9, a Graphical Fragment Assembly (GFA) file was produced. This file displays the final resolved assembly graph of all contig paths. However, the new versions of CANU has removed this feature. In this protocol we used CANU 1.9 and it produced a **SalmonBacteria.canu.unitigs.gfa** showing the contigs split at overlap junctions. We can use this to plot and visualize how the assembly would looks like (i.e. to get a graphical view of these "suggestedCircular" contigs). *It is important to notice that these graphs often would be missing edges and be over-fragmented.*

- To obtain a plot from a gfa file we can use the [Bandage](https://github.com/rrwick/Bandage) software. Bandage is installed as a singlularity container in Orion, we can load the software as follow:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ singularity exec /cvmfs/singularity.galaxyproject.org/b/a/bandage\:0.8.1--hc9558a2_2 Bandage --help
QStandardPaths: XDG_RUNTIME_DIR points to non-existing path '/run/user/4000', please create it with 0700 permissions.

  ____                  _                  
 |  _ \                | |                 
 | |_) | __ _ _ __   __| | __ _  __ _  ___ 
 |  _ < / _` | '_ \ / _` |/ _` |/ _` |/ _ \
 | |_) | (_| | | | | (_| | (_| | (_| |  __/
 |____/ \__,_|_| |_|\__,_|\__,_|\__, |\___|
                                 __/ |     
                                |___/      
Version: 0.8.1

Usage:    Bandage <command> [options]
          
Commands: <blank>      Launch the Bandage GUI
          load         Launch the Bandage GUI and load a graph file
          info         Display information about a graph
          image        Generate an image file of a graph
          querypaths   Output graph paths for BLAST queries
          reduce       Save a subgraph of a larger graph
          
Options:  --help       View this help message
          --helpall    View all command line settings
          --version    View Bandage version number
          
Online Bandage help: https://github.com/rrwick/Bandage/wiki
```

- Then we can feed this program with the **SalmonBacteria.canu.unitigs.gfa** and indicate to generate an image in png format from that graph.

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ singularity exec /cvmfs/singularity.galaxyproject.org/b/a/bandage\:0.8.1--hc9558a2_2 Bandage image SalmonBacteria.canu.unitigs.gfa SalmonBacteria.canu.unitigs.png
```

- The result is a png image displaying the union of "contigs" in the assembly graph. To open this file you need to copy to your computer or use the GUI Jupyterhub. The following plot is how this file looks like ![bandage](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/SalmonBacteria.canu.unitigs.png)

## Evaluate the length of the assembly, fragmentation, and completeness of the genome.

**As we noticed, the genomic assembly of this bacterial isolate resulted in 8 contigs. But what is the lenght of the total assembly, the largest conting and other metrics to evaluate the size and fragmentation of the genome?**

To answer this, we can obtain the total size (sum of all bases in the genome), the average lenght of the contigs and the N50-N90 statistics of the genome using the *assembly-stats* script developed by the [Sanger Institute](https://github.com/sanger-pathogens/assembly-stats).

- This software is in the conda-environment ONPTools previously loaded. *If you have not load this enviroment or was loged out the cluster, you need to activate this environmet again as in the following example:*. 
- The asssembly-stats command can be called by:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ source activate /net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools
(/net/cn-1/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ assembly-stats 
usage: stats [options] <list of fasta/q files>

Reports sequence length statistics from fasta and/or fastq files

options:
-l <int>
	Minimum length cutoff for each sequence.
	Sequences shorter than the cutoff will be ignored [1]
-s
	Print 'grep friendly' output
-t
	Print tab-delimited output
-u
	Print tab-delimited output with no header line
-v
	Print version and exit

```
- We can then give the **SalmonBacteria.canu.contigs.fasta** to this software and look the results:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ assembly-stats  SalmonBacteria.canu.contigs.fasta 
stats for SalmonBacteria.canu.contigs.fasta
sum = 3457932, n = 8, ave = 432241.50, largest = 3285151
N50 = 3285151, n = 1
N60 = 3285151, n = 1
N70 = 3285151, n = 1
N80 = 3285151, n = 1
N90 = 3285151, n = 1
N100 = 2535, n = 8
N_count = 0
Gaps = 0
```
**The total of bases in the assembly sum ~3.46 Mb, this is the final length of the assembly. The N50 (statistic that defines the assembly quality in terms of contiguity. It can be defined as: given a set of contigs, the N50 is the sequence length of the shortest contig at 50% of the total genome length...), is ~ 3.28 Mb in a single contig.**

Finally, we can assess the completeness of our genome. The most used strategy is to look for the presence of a set of single-copy orthologs genes commonly present in all bacteria (universal genes) and score the number of occurrences in our genome. 

### Evaluate genome completeness by BUSCO

[BUSCO](https://busco.ezlab.org/) (Benchmarking Universal Single-Copy Orthologs) is a tool that attempts to provide a quantitative assessment of the completeness in terms of expected gene content of a genome assembly, transcriptome, or annotated gene set. The results are simplified into categories of Complete and single-copy, Complete and duplicated, Fragmented, or Missing BUSCOs.

This software looks for a certain number of orthologous genes (BUSCOs) on a database and compares the total of these ortholog genes present in the genome we would like to evaluate. Then, it estimates the completeness based on the presence, duplication, fragmentation, or absence of these BUSCOS. For example (raw example), if the BUSCO database has 10 genes and the software only finds 9 of them in the query genome it scores completeness of the genome at 90 %.

BUSCO has developed different databases with common universal orthologs clusters for several organisms:
![buscoimg](https://github.com/avera1988/Genome_Assembly_lecture/blob/master/images/busco.png)

Busco will predict genes in the assembly (by prodigal) and then look for the USCOs of a certain taxonomical lineage using hmmer. It automatically identifies the closest taxonomical lineage and then download the BUSCOs database, however you can indicate and narrow the BUSCOs sarch to a prokaryote or eukaryote database by using the **--auto-lineage-prok** flag. 

- BUSCO is installed in Orion by a singularity container. We can use the following command to look into the busco options:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ singularity exec /cvmfs/singularity.galaxyproject.org/b/u/busco\:5.0.0--py_1 busco --help
sage: busco -i [SEQUENCE_FILE] -l [LINEAGE] -o [OUTPUT_NAME] -m [MODE] [OTHER OPTIONS]

Welcome to BUSCO 5.0.0: the Benchmarking Universal Single-Copy Ortholog assessment tool.
For more detailed usage information, please review the README file provided with this distribution and the BUSCO user guide.

optional arguments:
  -i FASTA FILE, --in FASTA FILE
                        Input sequence file in FASTA format. Can be an assembled genome or transcriptome (DNA), or protein sequences from an annotated gene set.
  -o OUTPUT, --out OUTPUT
                        Give your analysis run a recognisable short name. Output folders and files will be labelled with this name. WARNING: do not provide a path
  -m MODE, --mode MODE  Specify which BUSCO analysis mode to run.
                        There are three valid modes:
                        - geno or genome, for genome assemblies (DNA)
                        - tran or transcriptome, for transcriptome assemblies (DNA)
                        - prot or proteins, for annotated gene sets (protein)
  -l LINEAGE, --lineage_dataset LINEAGE
                        Specify the name of the BUSCO lineage to be used.
  --auto-lineage        Run auto-lineage to find optimum lineage path
  --auto-lineage-prok   Run auto-lineage just on non-eukaryote trees to find optimum lineage path
  --auto-lineage-euk    Run auto-placement just on eukaryote tree to find optimum lineage path
  -c N, --cpu N         Specify the number (N=integer) of threads/cores to use.
  -f, --force           Force rewriting of existing files. Must be used when output files with the provided name already exist.
  -r, --restart         Continue a run that had already partially completed.
  -q, --quiet           Disable the info logs, displays only errors
  --out_path OUTPUT_PATH
                        Optional location for results folder, excluding results folder name. Default is current working directory.
  --download_path DOWNLOAD_PATH
                        Specify local filepath for storing BUSCO dataset downloads
  --datasets_version DATASETS_VERSION
                        Specify the version of BUSCO datasets, e.g. odb10
  --download_base_url DOWNLOAD_BASE_URL
                        Set the url to the remote BUSCO dataset location
  --update-data         Download and replace with last versions all lineages datasets and files necessary to their automated selection
  --offline             To indicate that BUSCO cannot attempt to download files
  --metaeuk_parameters METAEUK_PARAMETERS
                        Pass additional arguments to Metaeuk for the first run. All arguments should be contained within a single pair of quotation marks, separated by commas. E.g. "--param1=1,--param2=2"
  --metaeuk_rerun_parameters METAEUK_RERUN_PARAMETERS
                        Pass additional arguments to Metaeuk for the second run. All arguments should be contained within a single pair of quotation marks, separated by commas. E.g. "--param1=1,--param2=2"
  -e N, --evalue N      E-value cutoff for BLAST searches. Allowed formats, 0.001 or 1e-03 (Default: 1e-03)
  --limit REGION_LIMIT  How many candidate regions (contig or transcript) to consider per BUSCO (default: 3)
  --augustus            Use augustus gene predictor for eukaryote runs
  --augustus_parameters AUGUSTUS_PARAMETERS
                        Pass additional arguments to Augustus. All arguments should be contained within a single pair of quotation marks, separated by commas. E.g. "--param1=1,--param2=2"
  --augustus_species AUGUSTUS_SPECIES
                        Specify a species for Augustus training.
  --long                Optimization Augustus self-training mode (Default: Off); adds considerably to the run time, but can improve results for some non-model organisms
  --config CONFIG_FILE  Provide a config file
  -v, --version         Show this version and exit
  -h, --help            Show this help message and exit
  --list-datasets       Print the list of available BUSCO datasets
  ```
 
We need to indicate the genome.fasta file we are using as a query, the lineage (in this case --auto-lineage-prok), the mode (genome) and the output prefix. **As BUSCO works more eficiently with multiple CPUs, the best option for running this program is by submitting a job in to the Orion queue.**

- The following busco.SLURM.sh script can be used for submiting BUSCO to the Orion queue.

```bash
#!/bin/bash

## Job name:
#SBATCH --job-name=BUSCOBacteria
#
## Wall time limit:
#SBATCH --time=00:30:00
#
## Other parameters:
#SBATCH --cpus-per-task 10
#SBATCH --mem=10G
#SBATCH --nodes 1
#SBATCH --partition=smallmem

## Set up job environment:

module --quiet purge  # Reset the modules to the system default

####Do some work:########

## For debuggin it is useful to print some info about the node,CPUs requested and when the job starts...
echo "Hello" $USER
echo "my submit directory is:"
echo $SLURM_SUBMIT_DIR
echo "this is the job:"
echo $SLURM_JOB_ID
echo "I am running on:"
echo $SLURM_NODELIST
echo "I am running with:"
echo $SLURM_CPUS_ON_NODE "cpus"
echo "Today is:"
date

## Copying data to local node for faster computation

cd $TMPDIR

#Check if $USER exists in $TMPDIR

if [[ -d $USER ]]
	then
        	echo "$USER exists on $TMPDIR"
	else
        	mkdir $USER
fi

echo "copying files to $TMPDIR/$USER/tmpDir_of.$SLURM_JOB_ID"

cd $USER
mkdir tmpDir_of.$SLURM_JOB_ID
cd tmpDir_of.$SLURM_JOB_ID

cp $SLURM_SUBMIT_DIR/*.canu.contigs.fasta .

fasta=$(ls -1|grep canu.contigs.fasta)

####RUNNING BUSCO####

echo "Busco starts at"
date +%d\ %b\ %T

singularity exec /cvmfs/singularity.galaxyproject.org/b/u/busco\:5.0.0--py_1 busco \
-i $fasta \
-o Salmon.bacteria.busco \
-m geno \
--auto-lineage-prok \
-c $SLURM_CPUS_ON_NODE

###########Moving results #####################

echo "moving results to" $SLURM_SUBMIT_DIR/

rm *.fasta #Remove fastq files
rm -r busco_downloads #Remove temp busco database downloads

time cp -r * $SLURM_SUBMIT_DIR/  #Copy all results to the submit directory

####Removing tmp dir#####

cd $TMPDIR/$USER/

rm -r tmpDir_of.$SLURM_JOB_ID

echo "I've done at"
date
```
*A copy of this script can be found at /mnt/SCRATCH/bio326-21/GenomeAssembly*

- Let's submit this script into Orion queue:

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ cp /mnt/SCRATCH/bio326-21/GenomeAssembly/busco.SLURM.sh .
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ sbatch busco.SLURM.sh
Submitted batch job 12720972
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ squeue -u $USER
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
          12720785     orion     bash bio326-2  R    1:48:19      1 cn-4 
          12720976  smallmem BUSCOBac bio326-2 PD       0:00      1 (Priority)
```

- After finishig, the job will create a **Salmon.bacteria.busco** directory. Let's enter to it and take a look:

*If your job has not started, it is taking a long time in the queue or proudce any error, you can find the results of the BUSCO analysis in the /mnt/SCRATCH/bio326-21/GenomeAssembly/Salmon.bacteria.busco folder, just copy and paste this folder to your $SCRATCH/GenomeAssembly/SalmonBacteria.canu.dir folder by:*

```bash
cp -r /mnt/SCRATCH/bio326-21/GenomeAssembly/Salmon.bacteria.busco $SCRATCH/GenomeAssemblyBio326/CANU.Assembly.dir/SalmonBacteria.canu.dir
```

```console
[bio326-21-0@cn-4 SalmonBacteria.canu.dir]$ cd Salmon.bacteria.busco/
[bio326-21-0@cn-4 Salmon.bacteria.busco]$ ls
auto_lineage  prodigal_output     run_pseudomonadales_odb10                                       short_summary.specific.pseudomonadales_odb10.Salmon.bacteria.busco.txt
logs          run_bacteria_odb10  short_summary.generic.bacteria_odb10.Salmon.bacteria.busco.txt
```
It creates a prodigal_output folder with all the predicted genes of the genome used as query as well as two directories with the hmmer results (run_bacteria_odb10 and run_pseudomonadales_odb10). BUSCO has automatically identified that our organism is a bacterium (short_summary.generic.bacteria_odb10.Salmon.bacteria.busco.txt) and it belongs to the pseudomonadales order (short_summary.specific.pseudomonadales_odb10.Salmon.bacteria.busco.txt). Then let's look into the summary to check the assembly completeness of our genome:

```console
bio326-21-0@login Salmon.bacteria.busco]$ more short_summary.specific.pseudomonadales_odb10.Salmon.bacteria.busco.txt 
# BUSCO version is: 5.0.0 
# The lineage dataset is: pseudomonadales_odb10 (Creation date: 2020-03-06, number of species: 159, number of BUSCOs: 782)
# Summarized benchmarking in BUSCO notation for file /home/work/bio326-21-0/tmpDir_of.12720976/SalmonBacteria.canu.contigs.fasta
# BUSCO was run in mode: genome
# Gene predictor used: prodigal

	***** Results: *****

	C:27.6%[S:27.6%,D:0.0%],F:17.9%,M:54.5%,n:782	   
	216	Complete BUSCOs (C)			   
	216	Complete and single-copy BUSCOs (S)	   
	0	Complete and duplicated BUSCOs (D)	   
	140	Fragmented BUSCOs (F)			   
	426	Missing BUSCOs (M)			   
	782	Total BUSCO groups searched	
```

**Accordingly to BUSCO, the bacterial genome recovered in this experiment is only 27 % complete. Most of the genes are missing or fragmented.**

## Improving the assembly by Racon and Medaka polisher tools...

Despite recent advances one of the main problems with Long-Read technologies is the increased error rate, especially in Oxford Nanopore data. One way to address this is the building of a consensus sequence. To build a consensus sequence all reads are aligned to the assembly and for each position in the assembly the nucleotide with the highest number of reads supporting it is chosen as the consensus nucleotide. This strategy often improves the genome contiguity allowing a more acurate resultion on gene prediction resulting in better BUSCO results. 

Often higher accuracy can be achieved by repeating the consensus-building several times and/or combining several consensus and error correction tools.

### [Racon](https://github.com/isovic/racon)

**The goal of Racon is to generate genomic consensus sequences which is of similar or better quality compared to the output generated by assembly methods which employ both error correction and consensus steps, while providing a speedup of several times compared to those methods.**

- Racon takes as input only three files: **contigs** in FASTA/FASTQ format, **reads** in FASTA/FASTQ format and **overlaps/alignments** between the reads and the contigs in MHAP/PAF/SAM format. This last step can be generated by using a sequence aligner tool as [minimap2](https://github.com/lh3/minimap2) or [BWA](http://bio-bwa.sourceforge.net/).

Let's polish our assembly using this strategy:

1. Return to our main SalmonBacteria.canu.dir

```console
[bio326-21-0@login ~]$ cd $SCRATCH/GenomeAssemblyBio326/CANU.Assembly.dir/SalmonBacteria.canu.dir
```

2. As we are doing some computational work let's ask for resources in the cluster as an interactive job. In this protocol we will use 10 cpus and 10Gb of ram:

```console
[bio326-21-0@login SalmonBacteria.canu.dir]$ srun --cpus-per-task 10 --mem=10G --time=02:00:00 --pty bash -i
srun: job 12724085 queued and waiting for resources
srun: job 12724085 has been allocated resources

Welcome to the NMBU Orion compute cluster environment.

You are logged in to a machine that can be used to access your home directory,
edit your scripts, manage your files, and submit jobs to the cluster environment.
Do not run any jobs on this machine, as they might be automatically terminated.

IMPORTANT:
  - Orion introduction: https://orion.nmbu.no/
  - Orion can handle small-scale projects. Need more CPU hours? Please consider
    applying for national infrastructure resources: https://www.sigma2.no/
  - Please, PLEASE do compress your fastq, vcf and other non-compressed files
    using i.e. pigz.

NEWS:
  - 2020-10-08: Orion has been re-built. We are still working out many details.
    Please email us if you miss anything, or notice any issues.

For any Orion related enquiry: orion-support@nmbu.no
PS: We are on Teams: https://bit.ly/orion-teams

[bio326-21-0@cn-17 SalmonBacteria.canu.dir]$
```

3. In order to use racon, we need a mapping (alingment) of the reads to assembly. We are using minimap2 to do this. Both minimap2 and racon are installed in the conda-environment ONPTools. For activating the conda we need first to load the module Miniconda3 and then activate the conda-environment as follow:

```console
[bio326-21-0@cn-17 SalmonBacteria.canu.dir]$ module load Miniconda3
[bio326-21-0@cn-17 SalmonBacteria.canu.dir]$ source activate /mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools/
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.canu.dir]$
```
*Remeber if your prompt changed showing the ONPTools on it means the conda environment is correctly loaded.*

4. Now let's see if minimap2 and racon are available. For this, we can display the fist lane (head -1) of the help in each software:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.canu.dir]$ minimap2 --help|head -1
Usage: minimap2 [options] <target.fa>|<target.idx> [query.fa] [...]
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.canu.dir]$ racon --help|head -1
usage: racon [options ...] <sequences> <overlaps> <target sequences>
```

5. CANU produce a file with the corrected reads as part of the pipeline (**SalmonBacteria.canu.correctedReads.fasta.gz**) so we will use those for mapping. Now let's move our reads and assembled contigs (**SalmonBacteria.canu.contigs.fasta**) into the $TMPDIR/$USER disk in this node  (cn-17) for faster computation:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.canu.dir]$ cp -t $TMPDIR/$USER *.contigs.fasta *.correctedReads.*
```
*Remember that \*.contigs.fasta\* stands for a regular expression that copies everything that has those elements in the name, the same for \*.correctedReads.\**

6. Then move to the $TMPDIR/$USER to see the files:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.canu.dir]$ cd $TMPDIR/$USER
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 bio326-21-0]$ ls
SalmonBacteria.canu.contigs.fasta  SalmonBacteria.canu.correctedReads.fasta.gz  singularity
```

7. Let's create a working directory and move our data there to keep this job tidy

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 bio326-21-0]$ mv -t working.dir.12724085/ *.fasta *.gz 
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 bio326-21-0]$ cd working.dir.12724085/
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ ls
SalmonBacteria.canu.contigs.fasta  SalmonBacteria.canu.correctedReads.fasta.gz
```

8. Now run minimap2 using all CPUs requested in the job ($SLURM_CPUS_ON_NODE = 10)

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 bio326-21-0]$ minimap2 -t $SLURM_CPUS_ON_NODE SalmonBacteria.canu.contigs.fasta SalmonBacteria.canu.correctedReads.fasta.gz > SalmonBacteria.canu.minimap2.paf
[M::mm_idx_gen::0.154*1.02] collected minimizers
[M::mm_idx_gen::0.189*1.67] sorted minimizers
[M::main::0.189*1.67] loaded/built the index for 8 target sequence(s)
[M::mm_mapopt_update::0.208*1.61] mid_occ = 17
[M::mm_idx_stat] kmer size: 15; skip: 10; is_hpc: 0; #seq: 8
[M::mm_idx_stat::0.221*1.57] distinct minimizers: 617183 (96.77% are singletons); average occurrences: 1.047; average spacing: 5.353
[M::worker_pipeline::3.437*6.07] mapped 16454 sequences
[M::main] Version: 2.17-r941
[M::main] CMD: minimap2 -t 10 SalmonBacteria.canu.contigs.fasta SalmonBacteria.canu.correctedReads.fasta.gz
[M::main] Real time: 3.448 sec; CPU: 20.871 sec; Peak RSS: 0.141 GB
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ ls
SalmonBacteria.canu.contigs.fasta  SalmonBacteria.canu.correctedReads.fasta.gz  SalmonBacteria.canu.minimap2.paf
```
We can see that now minimap2 generates the paf (Pairwise mApping Format) with the coordenates of mapping:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ head -3 SalmonBacteria.canu.minimap2.paf 
fd7335f1-5a8e-4d77-89b0-ff57182abb71	23589	4	23586	+	tig00000001	3285151	3153040	3176703	23110	23682	60	tp:A:P	cm:i:4166	s1:i:23104	s2:i:2329	dv:f:0.0033	rl:i:30
80a66614-47a6-4c4c-8cfa-58bc34d7206e	2863	36	2854	+	tig00000001	3285151	3131552	3134520	2215	2978	60	tp:A:P	cm:i:342	s1:i:2188	s2:i:41	dv:f:0.0303	rl:i:0
79bc3d18-bc51-4a81-8751-d4553abd0f6c	1026	4	1017	-	tig00000001	3285151	2914212	2915236	934	1025	60	tp:A:P	cm:i:159	s1:i:934	s2:i:0	dv:f:0.0112	rl:i:0
```

9. We are now ready to run racon:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ racon -t $SLURM_CPUS_ON_NODE SalmonBacteria.canu.correctedReads.fasta.gz SalmonBacteria.canu.minimap2.paf SalmonBacteria.canu.contigs.fasta > SalmonBacteria.canu.racon.consensus.fasta
[racon::Polisher::initialize] loaded target sequences 0.040048 s
[racon::Polisher::initialize] loaded sequences 1.234396 s
[racon::Polisher::initialize] loaded overlaps 0.028642 s
[racon::Polisher::initialize] aligning overlaps [====================] 4.834528 s
[racon::Polisher::initialize] transformed data into windows 0.039616 s
[racon::Polisher::polish] generating consensus [====================] 9.883945 s
[racon::Polisher::] total = 16.096524 s
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ ls
SalmonBacteria.canu.contigs.fasta  SalmonBacteria.canu.correctedReads.fasta.gz  SalmonBacteria.canu.minimap2.paf  SalmonBacteria.canu.racon.consensus.fasta
```
It looks like the software ran well and generated the consensus fasta file.

10. Let's compare the basic stats of the original assembly and the consensus by using the **assembly-stats** command:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ assembly-stats SalmonBacteria.canu.contigs.fasta SalmonBacteria.canu.racon.consensus.fasta 
stats for SalmonBacteria.canu.contigs.fasta
sum = 3457932, n = 8, ave = 432241.50, largest = 3285151
N50 = 3285151, n = 1
N60 = 3285151, n = 1
N70 = 3285151, n = 1
N80 = 3285151, n = 1
N90 = 3285151, n = 1
N100 = 2535, n = 8
N_count = 0
Gaps = 0
-------------------------------------------------------------------------------
stats for SalmonBacteria.canu.racon.consensus.fasta
sum = 3459138, n = 8, ave = 432392.25, largest = 3287128
N50 = 3287128, n = 1
N60 = 3287128, n = 1
N70 = 3287128, n = 1
N80 = 3287128, n = 1
N90 = 3287128, n = 1
N100 = 2235, n = 8
N_count = 0
Gaps = 0
```

It seems that the consensus shows a little more bases (3459138-3457932=1,206). But not a big improvment. What happen if we run busco?

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ singularity exec /cvmfs/singularity.galaxyproject.org/b/u/busco\:5.0.0--py_1 busco -i SalmonBacteria.canu.racon.consensus.fasta -o Busco_racon -m geno --auto-lineage-prok -c $SLURM_CPUS_ON_NODE

...

INFO:	

	--------------------------------------------------
	|Results from generic domain bacteria_odb10       |
	--------------------------------------------------
	|C:26.6%[S:26.6%,D:0.0%],F:54.8%,M:18.6%,n:124    |
	|33	Complete BUSCOs (C)                       |
	|33	Complete and single-copy BUSCOs (S)       |
	|0	Complete and duplicated BUSCOs (D)        |
	|68	Fragmented BUSCOs (F)                     |
	|23	Missing BUSCOs (M)                        |
	|124	Total BUSCO groups searched               |
	--------------------------------------------------

	--------------------------------------------------
	|Results from dataset pseudomonadales_odb10       |
	--------------------------------------------------
	|C:28.6%[S:28.6%,D:0.0%],F:18.8%,M:52.6%,n:782    |
	|224	Complete BUSCOs (C)                       |
	|224	Complete and single-copy BUSCOs (S)       |
	|0	Complete and duplicated BUSCOs (D)        |
	|147	Fragmented BUSCOs (F)                     |
	|411	Missing BUSCOs (M)                        |
	|782	Total BUSCO groups searched               |
	--------------------------------------------------
```

Let's compare the BUSCOs from this consensus and the original:


```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ more Busco_racon/short_summary.specific.pseudomonadales_odb10.Busco_racon.txt|grep -A 6 "C:" 
	C:28.6%[S:28.6%,D:0.0%],F:18.8%,M:52.6%,n:782	   
	224	Complete BUSCOs (C)			   
	224	Complete and single-copy BUSCOs (S)	   
	0	Complete and duplicated BUSCOs (D)	   
	147	Fragmented BUSCOs (F)			   
	411	Missing BUSCOs (M)			   
	782	Total BUSCO groups searched

(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ more $SCRATCH/Sessions/GenomeAssemblyBio326/CANU.Assembly.dir/SalmonBacteria.canu.dir/Salmon.bacteria.busco/short_summary.specific.pseudomonadales_odb10.Salmon.bacteria.busco.txt|grep -A 6 "C:"
	C:27.6%[S:27.6%,D:0.0%],F:17.9%,M:54.5%,n:782	   
	216	Complete BUSCOs (C)			   
	216	Complete and single-copy BUSCOs (S)	   
	0	Complete and duplicated BUSCOs (D)	   
	140	Fragmented BUSCOs (F)			   
	426	Missing BUSCOs (M)			   
	782	Total BUSCO groups searched
```

It looks like this "polishing" improves a bit the BUSCO from 27.6 % to 28.6 % and help to recover more genes. What happen if we use racon + Medaka another useful tool for polishing.

### [Medaka](https://nanoporetech.github.io/medaka/)

Medaka is a tool to create a consensus sequence of nanopore sequencing data. This task is performed using neural networks applied a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods whilst being much faster.

There is evidence that Medaka improves if racon is run on the assemble more than once. In this protocol we will run racon a second time on the assembly and then medaka.

1. Run a second round of racon using the same aproach as above but changing the original fasta file for the racon consensus file for mapping the reads and do the correction on it:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ minimap2 -t $SLURM_CPUS_ON_NODE SalmonBacteria.canu.racon.consensus.fasta SalmonBacteria.canu.correctedReads.fasta.gz > SalmonBacteria.racon.paf
[M::mm_idx_gen::0.159*1.02] collected minimizers
[M::mm_idx_gen::0.205*1.09] sorted minimizers
[M::main::0.205*1.09] loaded/built the index for 8 target sequence(s)
[M::mm_mapopt_update::0.218*1.09] mid_occ = 17
[M::mm_idx_stat] kmer size: 15; skip: 10; is_hpc: 0; #seq: 8
[M::mm_idx_stat::0.228*1.08] distinct minimizers: 617329 (96.77% are singletons); average occurrences: 1.047; average spacing: 5.353
[M::worker_pipeline::3.700*5.79] mapped 16454 sequences
[M::main] Version: 2.17-r941
[M::main] CMD: minimap2 -t 10 SalmonBacteria.canu.racon.consensus.fasta SalmonBacteria.canu.correctedReads.fasta.gz
[M::main] Real time: 3.713 sec; CPU: 21.451 sec; Peak RSS: 0.134 GB
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ racon -t $SLURM_CPUS_ON_NODE SalmonBacteria.canu.correctedReads.fasta.gz SalmonBacteria.racon.paf SalmonBacteria.canu.racon.consensus.fasta > SalmonBacteria.racon2.consensus.fasta
[racon::Polisher::initialize] loaded target sequences 0.037714 s
[racon::Polisher::initialize] loaded sequences 1.231584 s
[racon::Polisher::initialize] loaded overlaps 0.029424 s
[racon::Polisher::initialize] aligning overlaps [====================] 5.368575 s
[racon::Polisher::initialize] transformed data into windows 0.041861 s
[racon::Polisher::polish] generating consensus [====================] 10.453044 s
[racon::Polisher::] total = 17.200604 s
```
2. Let's check the requirements of Medaka:


```console
/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ medaka --help
usage: medaka [-h] [--version]
              {compress_bam,features,train,consensus,smolecule,consensus_from_features,fastrle,stitch,variant,snp,tools}
              ...

optional arguments:
  -h, --help            show this help message and exit
  --version             show program's version number and exit

subcommands:
  valid commands

  {compress_bam,features,train,consensus,smolecule,consensus_from_features,fastrle,stitch,variant,snp,tools}
                        additional help
    compress_bam        Compress an alignment into RLE form.
    features            Create features for inference.
    train               Train a model from features.
    consensus           Run inference from a trained model and alignments.
    smolecule           Create consensus sequences from single-molecule reads.
    consensus_from_features
                        Run inference from a trained model on existing
                        features.
    fastrle             Create run-length encoded fastq (lengths in quality
                        track).
    stitch              Stitch together output from medaka consensus into
                        final output.
    variant             Decode probabilities to VCF.
    snp                 Decode probabilities to SNPs.
    tools               tools subcommand.
```

We can see that medaka has multiple pipelines for running. In this protocol we will use the **medaka_consensus** option to generate the fasta consensus assembled contigs:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ medaka_consensus -help

medaka 1.2.3
------------

Assembly polishing via neural networks. The input assembly should be
preprocessed with racon.

medaka_consensus [-h] -i <fastx>

    -h  show this help text.
    -i  fastx input basecalls (required).
    -d  fasta input assembly (required).
    -o  output folder (default: medaka).
    -g  don't fill gaps in consensus with draft sequence.
    -m  medaka model, (default: r941_min_high_g360).
        Available: r103_min_high_g345, r103_min_high_g360, r103_prom_high_g360, r103_prom_snp_g3210, r103_prom_variant_g3210, r10_min_high_g303, r10_min_high_g340, r941_min_fast_g303, r941_min_high_g303, r941_min_high_g330, r941_min_high_g340_rle, r941_min_high_g344, r941_min_high_g351, r941_min_high_g360, r941_prom_fast_g303, r941_prom_high_g303, r941_prom_high_g330, r941_prom_high_g344, r941_prom_high_g360, r941_prom_high_g4011, r941_prom_snp_g303, r941_prom_snp_g322, r941_prom_snp_g360, r941_prom_variant_g303, r941_prom_variant_g322, r941_prom_variant_g360.
        Alternatively a .hdf file from 'medaka train'.
    -f  Force overwrite of outputs (default will reuse existing outputs).
    -t  number of threads with which to create features (default: 1).
    -b  batchsize, controls memory use (default: 100).
```

3. Medaka needs: The basecalled fastq file (-i), the assembled contigs (-d) and a model (-m) telling how the reads were generated and basecalled for training. In this experiment we used the MiniOn platform and the basecalling were performed by guppy using the fast mode, so the model we will use is the **r941_min_fast_g303**. Also is useful to name an output (-o) directory.

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ medaka_consensus -t $SLURM_CPUS_ON_NODE -i SalmonBacteria.canu.correctedReads.fasta.gz -d SalmonBacteria.racon2.consensus.fasta -o SalmonBacteria.medaka.out 
Checking program versions
This is medaka 1.2.3
Program    Version    Required   Pass     
bcftools   1.11       1.9        True     
bgzip      1.11       1.9        True     
minimap2   2.17       2.11       True     
samtools   1.11       1.9        True     
tabix      1.11       1.9        True     
.....
Polished assembly written to SalmonBacteria.medaka.out/consensus.fasta, have a nice day.
```
*As medaka runs multiple process not all are displayed in this protol...*

4. Now let's check the resulting folder and consensus fasta files in **SalmonBacteria.medaka.out/consensus.fasta**. By this we can compare the assembly statistics on the 3 experiments (i.e., raw canu, racon, and medaka):

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ cd SalmonBacteria.medaka.out/
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.medaka.out]$ assembly-stats ../SalmonBacteria.canu.contigs.fasta ../SalmonBacteria.canu.racon.consensus.fasta consensus.fasta
stats for ../SalmonBacteria.canu.contigs.fasta
sum = 3457932, n = 8, ave = 432241.50, largest = 3285151
N50 = 3285151, n = 1
N60 = 3285151, n = 1
N70 = 3285151, n = 1
N80 = 3285151, n = 1
N90 = 3285151, n = 1
N100 = 2535, n = 8
N_count = 0
Gaps = 0
-------------------------------------------------------------------------------
stats for ../SalmonBacteria.canu.racon.consensus.fasta
sum = 3459138, n = 8, ave = 432392.25, largest = 3287128
N50 = 3287128, n = 1
N60 = 3287128, n = 1
N70 = 3287128, n = 1
N80 = 3287128, n = 1
N90 = 3287128, n = 1
N100 = 2235, n = 8
N_count = 0
Gaps = 0
-------------------------------------------------------------------------------
stats for consensus.fasta
sum = 3460364, n = 8, ave = 432545.50, largest = 3288664
N50 = 3288664, n = 1
N60 = 3288664, n = 1
N70 = 3288664, n = 1
N80 = 3288664, n = 1
N90 = 3288664, n = 1
N100 = 2192, n = 8
N_count = 0
Gaps = 0
```

Again this polishing increased the number of bases. 

5. Now lets run BUSCO on this:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.medaka.out]$ singularity exec /cvmfs/singularity.galaxyproject.org/b/u/busco\:5.0.0--py_1 busco -i consensus.fasta -o Busco_medaka -m geno --auto-lineage-prok -c $SLURM_CPUS_ON_NODE
INFO:	***** Start a BUSCO v5.0.0 analysis, current time: 03/25/2021 20:57:49 *****

...

INFO:	

	--------------------------------------------------
	|Results from generic domain bacteria_odb10       |
	--------------------------------------------------
	|C:33.9%[S:33.9%,D:0.0%],F:50.8%,M:15.3%,n:124    |
	|42	Complete BUSCOs (C)                       |
	|42	Complete and single-copy BUSCOs (S)       |
	|0	Complete and duplicated BUSCOs (D)        |
	|63	Fragmented BUSCOs (F)                     |
	|19	Missing BUSCOs (M)                        |
	|124	Total BUSCO groups searched               |
	--------------------------------------------------

	--------------------------------------------------
	|Results from dataset pseudomonadales_odb10       |
	--------------------------------------------------
	|C:33.8%[S:33.8%,D:0.0%],F:18.8%,M:47.4%,n:782    |
	|264	Complete BUSCOs (C)                       |
	|264	Complete and single-copy BUSCOs (S)       |
	|0	Complete and duplicated BUSCOs (D)        |
	|147	Fragmented BUSCOs (F)                     |
	|371	Missing BUSCOs (M)                        |
	|782	Total BUSCO groups searched               |
	--------------------------------------------------
```

Now the assembly improves up to 33.8 % completeness with more BUSCOs found. 

**We can then use this final Medaka consensus assembly as our final bacterial draft genome to do produce some annotations and look for interesting metabolic features.**


6. Finally, remeber to copy all the results back to the $SCRATCH. 
But let's first get rid of the original contigs, reads and busco_downloads directories to not duplicate data and save disk space:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.medaka.out]$ rm -r busco_downloads/
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 SalmonBacteria.medaka.out]$ cd ..
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ rm -r *corrected*gz *.contigs.fasta busco_downloads
```
Then copy all the data to the $SCRATCH, clean the workdirectory and exit the job:

```console
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 bio326-21-0]$ cp -r working.dir.12724085/ $SCRATCH/GenomeAssemblyBio326/CANU.Assembly.dir/SalmonBacteria.canu.dir
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 working.dir.12724085]$ cd ..
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 bio326-21-0]$ rm -r working.dir.12724085/
(/mnt/SCRATCH/bio326-21/GenomeAssembly/condaenvironments/ONPTools) [bio326-21-0@cn-17 bio326-21-0]$ exit
```
Now just rename the working.dir to a something more useful:

```console
[bio326-21-0@login SalmonBacteria.canu.dir]$ mv working.dir.12724085/ Polishing.dir
```

**All this process can be submited via job using the /mnt/SCRATCH/bio326-21/GenomeAssembly/polishingNanopore.SLURM.sh

```console
[bio326-21-0@login SalmonBacteria.canu.dir]$ cp /mnt/SCRATCH/bio326-21/GenomeAssembly/polishingNanopore.SLURM.sh .
[bio326-21-0@login SalmonBacteria.canu.dir]$ sbatch polishingNanopore.SLURM.sh 
Submitted batch job 12724137	 
```

## Welcome to the bacterial genomic realm....Enjoy the Nanopore sequencing ....


